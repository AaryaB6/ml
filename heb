import numpy as np
import matplotlib.pyplot as plt


def hebbian_learning(inputs, outputs, learning_rate):
    # Initialize weights to small random values
    num_inputs = inputs.shape[1]
    weights = np.zeros(num_inputs)  # Weights will be a 1D array with size equal to the number of inputs

    
    for i in range(len(inputs)):
        # Update weights according to the Hebbian rule: w = w + Î· * x * y
        weights += learning_rate * inputs[i] * outputs[i]

    return weights


inputs = np.array([
    [1, 0, 1],  # Input 1
    [1, 1, 0],  # Input 2
    [0, 1, 1],  # Input 3
])


outputs = np.array([1, 0, 1])  # Desired outputs


learning_rate = 0.1


weights = hebbian_learning(inputs, outputs, learning_rate)


print("Final weights after Hebbian learning:", weights)


iterations = np.arange(1, len(inputs) + 1)
weight_values = np.zeros((len(iterations), len(weights)))


for i in range(len(iterations)):
    weight_values[i] = hebbian_learning(inputs[:i+1], outputs[:i+1], learning_rate)


plt.plot(iterations, weight_values[:, 0], label="Weight 1")
plt.plot(iterations, weight_values[:, 1], label="Weight 2")
plt.plot(iterations, weight_values[:, 2], label="Weight 3")
plt.xlabel('Iteration')
plt.ylabel('Weight Value')
plt.title('Weight Updates in Hebbian Learning')
plt.legend()
plt.grid(True)
plt.show()"""

  
